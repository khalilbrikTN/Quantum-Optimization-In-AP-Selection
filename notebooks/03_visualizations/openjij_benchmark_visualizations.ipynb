{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenJij Benchmark Visualizations\n",
    "\n",
    "This notebook generates high-resolution visualizations from Phase 1 and Phase 2 benchmark results.\n",
    "\n",
    "**Input Files:**\n",
    "- `data/results/phase1_openjij_parameters.xlsx` - QUBO parameter optimization results\n",
    "- `data/results/phase2_openjij_parameters.xlsx` - OpenJij annealing parameter optimization results\n",
    "- `data/results/pipeline_experiment_results.csv` - Importance metrics comparison results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to Python path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"✓ Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set high-quality plotting defaults\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "plt.rcParams['lines.linewidth'] = 3\n",
    "plt.rcParams['lines.markersize'] = 8\n",
    "plt.rcParams['xtick.major.width'] = 2\n",
    "plt.rcParams['ytick.major.width'] = 2\n",
    "plt.rcParams['xtick.major.size'] = 6\n",
    "plt.rcParams['ytick.major.size'] = 6\n",
    "plt.rcParams['grid.linewidth'] = 1.5\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "plt.rcParams['axes.labelsize'] = 13\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")\n",
    "print(\"✓ High-resolution plotting configured (DPI=300, thick lines)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Phase 1 and Phase 2 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "results_dir = project_root / 'data' / 'results'\n",
    "phase1_file = results_dir / 'phase1_openjij_parameters.xlsx'\n",
    "phase2_file = results_dir / 'phase2_openjij_parameters.xlsx'\n",
    "output_dir = results_dir / 'visualizations'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Loading benchmark results...\")\n",
    "\n",
    "# Load Phase 1 results\n",
    "if not phase1_file.exists():\n",
    "    raise FileNotFoundError(f\"Phase 1 file not found: {phase1_file}\")\n",
    "phase1_df = pd.read_excel(phase1_file)\n",
    "print(f\"✓ Loaded Phase 1 results: {len(phase1_df)} configurations\")\n",
    "print(f\"  Columns: {phase1_df.columns.tolist()}\")\n",
    "\n",
    "# Load Phase 2 results\n",
    "if not phase2_file.exists():\n",
    "    raise FileNotFoundError(f\"Phase 2 file not found: {phase2_file}\")\n",
    "phase2_df = pd.read_excel(phase2_file)\n",
    "print(f\"✓ Loaded Phase 2 results: {len(phase2_df)} configurations\")\n",
    "print(f\"  Columns: {phase2_df.columns.tolist()}\")\n",
    "\n",
    "# Extract parameter values for Phase 1\n",
    "k_values = sorted(phase1_df['k'].unique())\n",
    "alpha_values = sorted(phase1_df['alpha'].unique())\n",
    "penalty_values = sorted(phase1_df['penalty'].unique())\n",
    "\n",
    "print(f\"\\nPhase 1 parameter ranges:\")\n",
    "print(f\"  k: {k_values}\")\n",
    "print(f\"  alpha: {alpha_values}\")\n",
    "print(f\"  penalty: {penalty_values}\")\n",
    "\n",
    "# Extract parameter values for Phase 2\n",
    "num_sweeps_values = sorted(phase2_df['num_sweeps'].unique())\n",
    "num_reads_values = sorted(phase2_df['num_reads'].unique())\n",
    "beta_values = sorted(phase2_df['beta'].unique())\n",
    "gamma_values = sorted(phase2_df['gamma'].unique())\n",
    "\n",
    "print(f\"\\nPhase 2 parameter ranges:\")\n",
    "print(f\"  num_sweeps: {num_sweeps_values}\")\n",
    "print(f\"  num_reads: {num_reads_values}\")\n",
    "print(f\"  beta: {beta_values}\")\n",
    "print(f\"  gamma: {gamma_values}\")\n",
    "\n",
    "print(f\"\\n✓ Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 1 Visualizations: QUBO Parameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1: Mean 3D Error vs Number of APs (k) for Different Alpha Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    subset = phase1_df[phase1_df['alpha'] == alpha]\n",
    "    ax.plot(subset['k'], subset['mean_3d_error_m'], \n",
    "            marker='o', label=f'α={alpha}', linewidth=3)\n",
    "\n",
    "ax.set_xlabel('k (Number of APs)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Mean 3D Error (m)', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=12, frameon=True, shadow=True)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'phase1_fig1_error_vs_k.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 1 saved: phase1_fig1_error_vs_k.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2: Floor Accuracy vs Alpha for Different k Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "for k_val in k_values:\n",
    "    subset = phase1_df[phase1_df['k'] == k_val]\n",
    "    ax.plot(subset['alpha'], subset['floor_accuracy_0'], \n",
    "            marker='s', label=f'k={k_val}', linewidth=3)\n",
    "\n",
    "ax.set_xlabel('Alpha (α)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Floor Accuracy (exact)', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=12, frameon=True, shadow=True)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'phase1_fig2_floor_acc_vs_alpha.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 2 saved: phase1_fig2_floor_acc_vs_alpha.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3: Mean 3D Error Heatmap (k vs Alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "pivot_table = phase1_df.pivot_table(\n",
    "    values='mean_3d_error_m', \n",
    "    index='k', \n",
    "    columns='alpha', \n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "sns.heatmap(pivot_table, annot=True, fmt='.2f', cmap='RdYlGn_r', \n",
    "            ax=ax, cbar_kws={'label': 'Mean 3D Error (m)'}, \n",
    "            linewidths=2, linecolor='white',\n",
    "            annot_kws={'fontsize': 11, 'fontweight': 'bold'})\n",
    "\n",
    "ax.set_xlabel('Alpha (α)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('k (Number of APs)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'phase1_fig3_heatmap_k_alpha.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 3 saved: phase1_fig3_heatmap_k_alpha.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4: Positioning Accuracy vs Floor Accuracy (Penalty Effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "for penalty_val in penalty_values:\n",
    "    subset = phase1_df[phase1_df['penalty'] == penalty_val]\n",
    "    ax.scatter(subset['mean_3d_error_m'], subset['floor_accuracy_0'], \n",
    "               label=f'penalty={penalty_val}', s=200, alpha=0.7, \n",
    "               edgecolors='black', linewidths=1.5)\n",
    "\n",
    "ax.set_xlabel('Mean 3D Error (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Floor Accuracy (exact)', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=12, frameon=True, shadow=True)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'phase1_fig4_penalty_effect.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 4 saved: phase1_fig4_penalty_effect.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 2 Visualizations: OpenJij Annealing Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out infinite TTS values for visualization\n",
    "phase2_finite = phase2_df[phase2_df['tts_s'] != float('inf')].copy()\n",
    "\n",
    "# Find best configuration for marking\n",
    "phase2_sorted = phase2_finite.sort_values('tts_s')\n",
    "best_config = phase2_sorted.iloc[0]\n",
    "\n",
    "print(f\"Best OpenJij configuration (lowest TTS):\")\n",
    "print(f\"  num_sweeps: {int(best_config['num_sweeps'])}\")\n",
    "print(f\"  num_reads: {int(best_config['num_reads'])}\")\n",
    "print(f\"  beta: {best_config['beta']}\")\n",
    "print(f\"  gamma: {best_config['gamma']}\")\n",
    "print(f\"  TTS: {best_config['tts_s']:.3f}s\")\n",
    "print(f\"  Floor Accuracy: {best_config['floor_accuracy_0']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5: Time-to-Solution vs Number of Sweeps for Different num_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "for num_reads_val in num_reads_values:\n",
    "    subset = phase2_finite[phase2_finite['num_reads'] == num_reads_val]\n",
    "    # Group by num_sweeps and take mean of TTS\n",
    "    grouped = subset.groupby('num_sweeps')['tts_s'].mean().reset_index()\n",
    "    ax.plot(grouped['num_sweeps'], grouped['tts_s'], \n",
    "            marker='o', label=f'reads={num_reads_val}', linewidth=3)\n",
    "\n",
    "ax.set_xlabel('Number of Sweeps', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Time-to-Solution (s)', fontsize=14, fontweight='bold')\n",
    "ax.set_yscale('log')\n",
    "ax.legend(fontsize=12, frameon=True, shadow=True)\n",
    "ax.grid(True, alpha=0.3, which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'phase2_fig5_tts_vs_sweeps.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 5 saved: phase2_fig5_tts_vs_sweeps.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 6: Success Rate vs Number of Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "ax.scatter(phase2_finite['num_reads'], phase2_finite['success_rate'], \n",
    "           alpha=0.6, s=200, edgecolors='black', linewidths=1.5)\n",
    "\n",
    "ax.set_xlabel('Number of Reads', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Success Rate', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'phase2_fig6_success_vs_reads.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 6 saved: phase2_fig6_success_vs_reads.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7: Time-to-Solution vs Beta (Inverse Temperature) for Different Gamma Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "for gamma_val in gamma_values:\n",
    "    subset = phase2_finite[phase2_finite['gamma'] == gamma_val]\n",
    "    # Group by beta and take mean of TTS\n",
    "    grouped = subset.groupby('beta')['tts_s'].mean().reset_index()\n",
    "    ax.plot(grouped['beta'], grouped['tts_s'], \n",
    "            marker='s', label=f'γ={gamma_val}', linewidth=3)\n",
    "\n",
    "ax.set_xlabel('Beta (Inverse Temperature)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Time-to-Solution (s)', fontsize=14, fontweight='bold')\n",
    "ax.set_yscale('log')\n",
    "ax.legend(fontsize=12, frameon=True, shadow=True)\n",
    "ax.grid(True, alpha=0.3, which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'phase2_fig7_tts_vs_beta.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 7 saved: phase2_fig7_tts_vs_beta.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 8: Floor Accuracy vs Time-to-Solution (Colored by num_sweeps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "\n",
    "scatter = ax.scatter(phase2_finite['tts_s'], phase2_finite['floor_accuracy_0'], \n",
    "                     c=phase2_finite['num_sweeps'], cmap='viridis', \n",
    "                     s=200, alpha=0.7, edgecolors='black', linewidths=1.5)\n",
    "\n",
    "ax.set_xlabel('Time-to-Solution (s)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Floor Accuracy (exact)', fontsize=14, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('num_sweeps', fontsize=13, fontweight='bold')\n",
    "cbar.ax.tick_params(labelsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'phase2_fig8_floor_acc_vs_tts.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 8 saved: phase2_fig8_floor_acc_vs_tts.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 9: Mean 3D Error vs Time-to-Solution (Colored by Success Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "\n",
    "scatter = ax.scatter(phase2_finite['tts_s'], phase2_finite['mean_3d_error_m'], \n",
    "                     c=phase2_finite['success_rate'], cmap='RdYlGn', \n",
    "                     s=200, alpha=0.7, edgecolors='black', linewidths=1.5,\n",
    "                     vmin=0, vmax=1)\n",
    "\n",
    "ax.set_xlabel('Time-to-Solution (s)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Mean 3D Error (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('Success Rate', fontsize=13, fontweight='bold')\n",
    "cbar.ax.tick_params(labelsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'phase2_fig9_error_vs_tts.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 9 saved: phase2_fig9_error_vs_tts.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 10: Optimization Trade-off (TTS vs Floor Accuracy with Best Configuration Marked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# Plot all configurations\n",
    "ax.scatter(phase2_finite['tts_s'], phase2_finite['floor_accuracy_0'], \n",
    "           s=200, alpha=0.6, edgecolors='black', linewidths=1.5,\n",
    "           label='All Configurations', color='steelblue')\n",
    "\n",
    "# Mark best configuration\n",
    "ax.scatter(best_config['tts_s'], best_config['floor_accuracy_0'], \n",
    "           s=500, color='red', marker='*', edgecolors='black', \n",
    "           linewidths=2.5, label='Best Configuration', zorder=10)\n",
    "\n",
    "ax.set_xlabel('Time-to-Solution (s)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Floor Accuracy (exact)', fontsize=14, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "ax.legend(fontsize=12, frameon=True, shadow=True)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'phase2_fig10_pareto_front.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 10 saved: phase2_fig10_pareto_front.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Importance Metrics Comparison\n",
    "\n",
    "Comparison of different importance methods (Entropy, Variance, Max, Average) for k=20 APs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load importance metrics comparison results\n",
    "pipeline_file = results_dir / 'pipeline_experiment_results.csv'\n",
    "\n",
    "if not pipeline_file.exists():\n",
    "    raise FileNotFoundError(f\"Pipeline results file not found: {pipeline_file}\")\n",
    "\n",
    "pipeline_df = pd.read_csv(pipeline_file)\n",
    "\n",
    "# Filter for k=20 only and specific methods from the table\n",
    "k20_df = pipeline_df[pipeline_df['Num_APs'] == 20].copy()\n",
    "\n",
    "# Filter for the four methods in the table (excluding MUTUAL_INFO)\n",
    "importance_methods = ['ENTROPY', 'VARIANCE', 'MAX', 'AVERAGE']\n",
    "k20_df = k20_df[k20_df['Importance_Method'].isin(importance_methods)]\n",
    "\n",
    "# Convert to percentages for floor accuracy\n",
    "k20_df['Floor_Accuracy_Exact_Pct'] = k20_df['Floor_Accuracy_0'] * 100\n",
    "k20_df['Floor_Accuracy_Plus1_Pct'] = k20_df['Floor_Accuracy_1'] * 100\n",
    "\n",
    "# Sort by method name for consistent ordering\n",
    "k20_df = k20_df.sort_values('Importance_Method')\n",
    "\n",
    "print(\"✓ Loaded pipeline results for importance metrics comparison\")\n",
    "print(f\"  Methods: {k20_df['Importance_Method'].tolist()}\")\n",
    "print(f\"\\nData preview:\")\n",
    "print(k20_df[['Importance_Method', 'Median_3D_Error_m', 'Floor_Accuracy_Exact_Pct', 'Floor_Accuracy_Plus1_Pct']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 11: Median 3D Positioning Error by Importance Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# Create bar chart\n",
    "colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D']\n",
    "bars = ax.bar(k20_df['Importance_Method'], k20_df['Median_3D_Error_m'], \n",
    "              color=colors, edgecolor='black', linewidth=2, alpha=0.8)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.2f}m',\n",
    "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Importance Method', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Median 3D Error (m)', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'importance_fig11_median_error.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 11 saved: importance_fig11_median_error.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 12: Floor Classification Accuracy by Importance Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "\n",
    "# Set up bar positions\n",
    "x = np.arange(len(k20_df))\n",
    "width = 0.35\n",
    "\n",
    "# Create grouped bars\n",
    "bars1 = ax.bar(x - width/2, k20_df['Floor_Accuracy_Exact_Pct'], width, \n",
    "               label='Exact Floor', color='#2E86AB', edgecolor='black', \n",
    "               linewidth=2, alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, k20_df['Floor_Accuracy_Plus1_Pct'], width, \n",
    "               label='±1 Floor', color='#F18F01', edgecolor='black', \n",
    "               linewidth=2, alpha=0.8)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1f}%',\n",
    "                ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Importance Method', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Floor Accuracy (%)', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(k20_df['Importance_Method'])\n",
    "ax.legend(fontsize=12, frameon=True, shadow=True)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'importance_fig12_floor_accuracy.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 12 saved: importance_fig12_floor_accuracy.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 13: Trade-off Between Positioning Error and Floor Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# Create scatter plot with different colors for each method\n",
    "colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D']\n",
    "\n",
    "for idx, (_, row) in enumerate(k20_df.iterrows()):\n",
    "    ax.scatter(row['Median_3D_Error_m'], row['Floor_Accuracy_Exact_Pct'], \n",
    "               s=400, color=colors[idx], edgecolor='black', linewidth=2.5,\n",
    "               label=row['Importance_Method'], alpha=0.8, zorder=3)\n",
    "    \n",
    "    # Add method name annotation\n",
    "    ax.annotate(row['Importance_Method'], \n",
    "                (row['Median_3D_Error_m'], row['Floor_Accuracy_Exact_Pct']),\n",
    "                xytext=(10, 10), textcoords='offset points',\n",
    "                fontsize=11, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.5', facecolor=colors[idx], \n",
    "                         alpha=0.3, edgecolor='black', linewidth=1.5))\n",
    "\n",
    "ax.set_xlabel('Median 3D Error (m)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Exact Floor Accuracy (%)', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'importance_fig13_error_vs_accuracy.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 13 saved: importance_fig13_error_vs_accuracy.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14: Comprehensive Performance Comparison (Radar Chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "# Metrics to plot (inverted error so higher is better for all metrics)\n",
    "# Normalize to 0-100 scale\n",
    "max_error = k20_df['Median_3D_Error_m'].max()\n",
    "k20_df['Positioning_Score'] = 100 * (1 - k20_df['Median_3D_Error_m'] / max_error)\n",
    "\n",
    "categories = ['Positioning\\nAccuracy', 'Exact Floor\\nAccuracy', '±1 Floor\\nAccuracy']\n",
    "num_vars = len(categories)\n",
    "\n",
    "# Compute angle for each axis\n",
    "angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "angles += angles[:1]  # Complete the circle\n",
    "\n",
    "# Plot each importance method\n",
    "colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D']\n",
    "for idx, (_, row) in enumerate(k20_df.iterrows()):\n",
    "    values = [\n",
    "        row['Positioning_Score'],\n",
    "        row['Floor_Accuracy_Exact_Pct'],\n",
    "        row['Floor_Accuracy_Plus1_Pct']\n",
    "    ]\n",
    "    values += values[:1]  # Complete the circle\n",
    "    \n",
    "    ax.plot(angles, values, 'o-', linewidth=3, \n",
    "            label=row['Importance_Method'], color=colors[idx])\n",
    "    ax.fill(angles, values, alpha=0.15, color=colors[idx])\n",
    "\n",
    "# Set category labels\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories, fontsize=13, fontweight='bold')\n",
    "\n",
    "# Set radial limits\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_yticks([20, 40, 60, 80, 100])\n",
    "ax.set_yticklabels(['20', '40', '60', '80', '100'], fontsize=11)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=12, \n",
    "          frameon=True, shadow=True)\n",
    "\n",
    "# Add grid\n",
    "ax.grid(True, linewidth=1.5, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'importance_fig14_radar_chart.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 14 saved: importance_fig14_radar_chart.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"VISUALIZATION GENERATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nPhase 1 Figures (4 total):\")\n",
    "print(f\"  1. Mean 3D Error vs k (different alphas)\")\n",
    "print(f\"  2. Floor Accuracy vs alpha (different k values)\")\n",
    "print(f\"  3. Heatmap of Mean 3D Error (k vs alpha)\")\n",
    "print(f\"  4. Penalty effect (positioning vs floor accuracy)\")\n",
    "print(f\"\\nPhase 2 Figures (6 total):\")\n",
    "print(f\"  5. TTS vs num_sweeps (different num_reads)\")\n",
    "print(f\"  6. Success Rate vs num_reads\")\n",
    "print(f\"  7. TTS vs beta (different gamma values)\")\n",
    "print(f\"  8. Floor Accuracy vs TTS (colored by num_sweeps)\")\n",
    "print(f\"  9. Mean 3D Error vs TTS (colored by success rate)\")\n",
    "print(f\"  10. Pareto front with best configuration marked\")\n",
    "print(f\"\\nImportance Metrics Comparison (4 total):\")\n",
    "print(f\"  11. Median 3D Error by importance method\")\n",
    "print(f\"  12. Floor Accuracy by importance method (grouped bars)\")\n",
    "print(f\"  13. Trade-off scatter plot (error vs accuracy)\")\n",
    "print(f\"  14. Comprehensive radar chart comparison\")\n",
    "print(f\"\\nAll figures saved to: {output_dir}\")\n",
    "print(f\"  Total figures: 14\")\n",
    "print(f\"  Resolution: 300 DPI\")\n",
    "print(f\"  Line thickness: 3.0\")\n",
    "print(f\"  No titles (as requested)\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
