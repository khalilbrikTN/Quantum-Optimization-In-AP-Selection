{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Visualizations\n",
    "\n",
    "This notebook generates publication-ready visualizations for the research paper.\n",
    "\n",
    "**Input Files:**\n",
    "- `data/results/phase1_openjij_parameters.xlsx` - QUBO parameter optimization results\n",
    "- `data/results/phase2_openjij_parameters.xlsx` - OpenJij annealing parameter optimization results\n",
    "- `data/results/pipeline_experiment_results.csv` - Importance metrics comparison results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Project root: c:\\Users\\AUC\\Desktop\\Thesis\\Quantum-Optimization-In-AP-Selection\n"
     ]
    }
   ],
   "source": [
    "# Add project root to Python path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"âœ“ Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All libraries imported successfully\n",
      "âœ“ Publication-quality plotting configured (DPI=300)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set publication-quality plotting defaults\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "plt.rcParams['lines.linewidth'] = 3\n",
    "plt.rcParams['lines.markersize'] = 8\n",
    "plt.rcParams['xtick.major.width'] = 2\n",
    "plt.rcParams['ytick.major.width'] = 2\n",
    "plt.rcParams['xtick.major.size'] = 6\n",
    "plt.rcParams['ytick.major.size'] = 6\n",
    "plt.rcParams['grid.linewidth'] = 1.5\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "plt.rcParams['axes.labelsize'] = 13\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully\")\n",
    "print(\"âœ“ Publication-quality plotting configured (DPI=300)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading benchmark results...\n",
      "âœ“ Loaded Phase 1 results: 96 configurations\n",
      "âœ“ Loaded Phase 2 results: 144 configurations\n",
      "âœ“ Loaded pipeline results: 5 configurations\n",
      "\n",
      "âœ“ Output directory: c:\\Users\\AUC\\Desktop\\Thesis\\Quantum-Optimization-In-AP-Selection\\data\\results\\visualizations\\paper\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "results_dir = project_root / 'data' / 'results'\n",
    "phase1_file = results_dir / 'phase1_openjij_parameters.xlsx'\n",
    "phase2_file = results_dir / 'phase2_openjij_parameters.xlsx'\n",
    "pipeline_file = results_dir / 'pipeline_experiment_results.csv'\n",
    "output_dir = results_dir / 'visualizations' / 'paper'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Loading benchmark results...\")\n",
    "\n",
    "# Load Phase 1 results\n",
    "if not phase1_file.exists():\n",
    "    raise FileNotFoundError(f\"Phase 1 file not found: {phase1_file}\")\n",
    "phase1_df = pd.read_excel(phase1_file)\n",
    "print(f\"âœ“ Loaded Phase 1 results: {len(phase1_df)} configurations\")\n",
    "\n",
    "# Load Phase 2 results\n",
    "if not phase2_file.exists():\n",
    "    raise FileNotFoundError(f\"Phase 2 file not found: {phase2_file}\")\n",
    "phase2_df = pd.read_excel(phase2_file)\n",
    "print(f\"âœ“ Loaded Phase 2 results: {len(phase2_df)} configurations\")\n",
    "\n",
    "# Load importance metrics comparison results\n",
    "if not pipeline_file.exists():\n",
    "    raise FileNotFoundError(f\"Pipeline results file not found: {pipeline_file}\")\n",
    "pipeline_df = pd.read_csv(pipeline_file)\n",
    "print(f\"âœ“ Loaded pipeline results: {len(pipeline_df)} configurations\")\n",
    "\n",
    "print(f\"\\nâœ“ Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# DATA QUALITY REPORT AND SUMMARY STATISTICS\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"DATA QUALITY REPORT\")\nprint(\"=\"*80)\n\n# Phase 1 Summary\nprint(\"\\n--- PHASE 1: QUBO PARAMETERS ---\")\nprint(f\"Configurations: {len(phase1_df)}\")\nprint(f\"Missing values:\\n{phase1_df.isnull().sum()}\")\nprint(f\"\\nPerformance Metrics:\")\nprint(f\"  Mean 3D Error: {phase1_df['mean_3d_error_m'].min():.2f}m (best) to {phase1_df['mean_3d_error_m'].max():.2f}m (worst)\")\nprint(f\"  Floor Accuracy: {phase1_df['floor_accuracy_0'].min():.2%} to {phase1_df['floor_accuracy_0'].max():.2%}\")\nprint(f\"\\nBest configuration:\")\nbest_phase1 = phase1_df.sort_values('mean_3d_error_m').iloc[0]\nprint(f\"  k={int(best_phase1['k'])}, alpha={best_phase1['alpha']}, penalty={best_phase1['penalty']}\")\nprint(f\"  Mean Error: {best_phase1['mean_3d_error_m']:.2f}m\")\nprint(f\"  Floor Accuracy: {best_phase1['floor_accuracy_0']:.2%}\")\n\n# Phase 2 Summary\nprint(\"\\n--- PHASE 2: OPENJIJ PARAMETERS ---\")\nprint(f\"Configurations (finite TTS): {len(phase2_finite)}\")\nprint(f\"Configurations (infinite TTS): {len(phase2_df) - len(phase2_finite)}\")\nprint(f\"\\nPerformance Metrics:\")\nprint(f\"  TTS: {phase2_finite['tts_s'].min():.4f}s (best) to {phase2_finite['tts_s'].max():.4f}s (worst)\")\nprint(f\"  Success Rate: {phase2_finite['success_rate'].min():.2%} to {phase2_finite['success_rate'].max():.2%}\")\nprint(f\"  Mean 3D Error: {phase2_finite['mean_3d_error_m'].min():.2f}m to {phase2_finite['mean_3d_error_m'].max():.2f}m\")\nprint(f\"\\nBest configuration (by TTS):\")\nbest_phase2 = phase2_finite.sort_values('tts_s').iloc[0]\nprint(f\"  sweeps={int(best_phase2['num_sweeps'])}, reads={int(best_phase2['num_reads'])}, beta={best_phase2['beta']}, gamma={best_phase2['gamma']}\")\nprint(f\"  TTS: {best_phase2['tts_s']:.4f}s, Success Rate: {best_phase2['success_rate']:.2%}\")\n\n# Importance Methods Summary\nprint(\"\\n--- IMPORTANCE METHODS COMPARISON ---\")\nprint(k20_df[['Importance_Method', 'Median_3D_Error_m', 'Floor_Accuracy_Exact_Pct']].to_string(index=False))\nprint(f\"\\nBest method (by Median Error): {k20_df.sort_values('Median_3D_Error_m').iloc[0]['Importance_Method']}\")\nprint(f\"Best method (by Floor Accuracy): {k20_df.sort_values('Floor_Accuracy_Exact_Pct', ascending=False).iloc[0]['Importance_Method']}\")\n\nprint(\"\\n\" + \"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# DATA PREPROCESSING AND QUALITY CHECKS\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"DATA PREPROCESSING\")\nprint(\"=\"*80)\n\n# 1. Filter Phase 2 for finite TTS values\nprint(\"\\nPhase 2: Filtering infinite TTS values...\")\nprint(f\"  Original rows: {len(phase2_df)}\")\nprint(f\"  Infinite TTS values: {np.isinf(phase2_df['tts_s']).sum()}\")\n\nphase2_finite = phase2_df[np.isfinite(phase2_df['tts_s'])].copy()\nprint(f\"  Filtered rows: {len(phase2_finite)}\")\nprint(f\"  TTS range: {phase2_finite['tts_s'].min():.4f}s to {phase2_finite['tts_s'].max():.4f}s\")\n\n# 2. Filter pipeline data for k=20 only\nprint(\"\\nPipeline: Filtering for k=20 configurations...\")\nk20_df = pipeline_df[pipeline_df['Num_APs'] == 20].copy()\n\n# Filter to only include Entropy, Variance, Max, and Average methods\nprint(\"\\nImportance Methods: Filtering to show only Entropy, Variance, Max, and Average...\")\nprint(f\"  Original methods: {k20_df['Importance_Method'].tolist()}\")\nselected_methods = ['Entropy', 'Variance', 'Max', 'Average']\nk20_df = k20_df[k20_df['Importance_Method'].isin(selected_methods)].copy()\nprint(f\"  Filtered methods: {k20_df['Importance_Method'].tolist()}\")\n\n# Convert to percentages\nk20_df['Floor_Accuracy_Exact_Pct'] = k20_df['Floor_Accuracy_0'] * 100\nk20_df['Floor_Accuracy_Plus1_Pct'] = k20_df['Floor_Accuracy_1'] * 100\n\nprint(\"\\nâœ“ Data preprocessing complete\")\nprint(\"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Data Preprocessing and Quality Checks",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 1: QUBO Parameter Optimization\n",
    "\n",
    "Clear 2-variable visualizations showing the impact of each parameter on system performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1: Number of APs (k) vs Mean 3D Positioning Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(10, 7))\n\n# Aggregate with error bars (mean Â± std) and min/max range\ngrouped = phase1_df.groupby('k').agg({\n    'mean_3d_error_m': ['mean', 'std', 'min', 'max']\n}).reset_index()\ngrouped.columns = ['k', 'mean', 'std', 'min', 'max']\n\n# Plot with error bars\nax.errorbar(grouped['k'], grouped['mean'], yerr=grouped['std'],\n            marker='o', linewidth=3, capsize=8, capthick=2, \n            color='#2E86AB', markersize=10, label='Mean Â± Std')\n\n# Add shaded region for min/max range\nax.fill_between(grouped['k'], grouped['min'], grouped['max'],\n                alpha=0.2, color='#2E86AB', label='Min-Max Range')\n\nax.set_xlabel('k (Number of APs)', fontsize=14, fontweight='bold')\nax.set_ylabel('Mean 3D Error (m)', fontsize=14, fontweight='bold')\nax.legend(fontsize=11, loc='best')\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(output_dir / 'fig1_k_vs_error.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"âœ“ Figure 1 saved: fig1_k_vs_error.png (with error bars)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2: Number of APs (k) vs Floor Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(10, 7))\n\n# Aggregate with error bars\ngrouped = phase1_df.groupby('k').agg({\n    'floor_accuracy_0': ['mean', 'std', 'min', 'max']\n}).reset_index()\ngrouped.columns = ['k', 'mean', 'std', 'min', 'max']\ngrouped['mean_pct'] = grouped['mean'] * 100\ngrouped['std_pct'] = grouped['std'] * 100\ngrouped['min_pct'] = grouped['min'] * 100\ngrouped['max_pct'] = grouped['max'] * 100\n\n# Plot with error bars\nax.errorbar(grouped['k'], grouped['mean_pct'], yerr=grouped['std_pct'],\n            marker='s', linewidth=3, capsize=8, capthick=2, \n            color='#A23B72', markersize=10, label='Mean Â± Std')\n\n# Add shaded region for min/max range\nax.fill_between(grouped['k'], grouped['min_pct'], grouped['max_pct'],\n                alpha=0.2, color='#A23B72', label='Min-Max Range')\n\nax.set_xlabel('k (Number of APs)', fontsize=14, fontweight='bold')\nax.set_ylabel('Floor Accuracy (%)', fontsize=14, fontweight='bold')\nax.legend(fontsize=11, loc='best')\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(output_dir / 'k_vs_floor_acc.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"âœ“ Figure 2 saved: k_vs_floor_acc.png (with error bars)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3: Alpha (Importance Threshold) vs Mean 3D Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(10, 7))\n\n# Aggregate with error bars\ngrouped = phase1_df.groupby('alpha').agg({\n    'mean_3d_error_m': ['mean', 'std', 'min', 'max']\n}).reset_index()\ngrouped.columns = ['alpha', 'mean', 'std', 'min', 'max']\n\n# Plot with error bars\nax.errorbar(grouped['alpha'], grouped['mean'], yerr=grouped['std'],\n            marker='D', linewidth=3, capsize=8, capthick=2, \n            color='#F18F01', markersize=10, label='Mean Â± Std')\n\n# Add shaded region for min/max range\nax.fill_between(grouped['alpha'], grouped['min'], grouped['max'],\n                alpha=0.2, color='#F18F01', label='Min-Max Range')\n\nax.set_xlabel('Alpha (Î±) - Importance Threshold', fontsize=14, fontweight='bold')\nax.set_ylabel('Mean 3D Error (m)', fontsize=14, fontweight='bold')\nax.legend(fontsize=11, loc='best')\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(output_dir / 'alpha_vs_error.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"âœ“ Figure 3 saved: alpha_vs_error.png (with error bars)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4: Penalty Weight vs Floor Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(10, 7))\n\n# Aggregate with error bars\ngrouped = phase1_df.groupby('penalty').agg({\n    'floor_accuracy_0': ['mean', 'std', 'min', 'max']\n}).reset_index()\ngrouped.columns = ['penalty', 'mean', 'std', 'min', 'max']\ngrouped['mean_pct'] = grouped['mean'] * 100\ngrouped['std_pct'] = grouped['std'] * 100\ngrouped['min_pct'] = grouped['min'] * 100\ngrouped['max_pct'] = grouped['max'] * 100\n\n# Plot with error bars\nax.errorbar(grouped['penalty'], grouped['mean_pct'], yerr=grouped['std_pct'],\n            marker='^', linewidth=3, capsize=8, capthick=2, \n            color='#C73E1D', markersize=10, label='Mean Â± Std')\n\n# Add shaded region for min/max range\nax.fill_between(grouped['penalty'], grouped['min_pct'], grouped['max_pct'],\n                alpha=0.2, color='#C73E1D', label='Min-Max Range')\n\nax.set_xlabel('Penalty Weight', fontsize=14, fontweight='bold')\nax.set_ylabel('Floor Accuracy (%)', fontsize=14, fontweight='bold')\nax.legend(fontsize=11, loc='best')\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(output_dir / 'penalty_vs_floor_acc.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"âœ“ Figure 4 saved: penalty_vs_floor_acc.png (with error bars)\")"
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# COMPREHENSIVE PHASE 1 ANALYSIS (4-PANEL FIGURE)\n# ============================================================================\n\nfig = plt.figure(figsize=(16, 12))\ngs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)\n\n# Panel A: Error vs k with error bars (mean Â± std) and min/max range\nax1 = fig.add_subplot(gs[0, 0])\ngrouped = phase1_df.groupby('k').agg({\n    'mean_3d_error_m': ['mean', 'std', 'min', 'max']\n}).reset_index()\ngrouped.columns = ['k', 'mean', 'std', 'min', 'max']\n\nax1.errorbar(grouped['k'], grouped['mean'], \n             yerr=grouped['std'],\n             marker='o', linewidth=3, capsize=8, capthick=2, \n             color='#2E86AB', markersize=10, label='Mean Â± Std')\nax1.fill_between(grouped['k'], \n                  grouped['min'],\n                  grouped['max'],\n                  alpha=0.2, color='#2E86AB', label='Min-Max Range')\nax1.set_xlabel('k (Number of APs)', fontsize=13, fontweight='bold')\nax1.set_ylabel('Mean 3D Error (m)', fontsize=13, fontweight='bold')\nax1.legend(fontsize=10, loc='best')\nax1.grid(True, alpha=0.3)\nax1.text(0.02, 0.98, 'A', transform=ax1.transAxes, \n         fontsize=20, fontweight='bold', va='top',\n         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n\n# Panel B: Heatmap of error (k vs alpha)\nax2 = fig.add_subplot(gs[0, 1])\npivot = phase1_df.pivot_table(values='mean_3d_error_m', index='alpha', columns='k', aggfunc='mean')\nsns.heatmap(pivot, annot=True, fmt='.1f', cmap='RdYlGn_r', \n            ax=ax2, cbar_kws={'label': 'Mean 3D Error (m)'}, vmin=pivot.min().min(), vmax=pivot.max().max())\nax2.set_xlabel('k (Number of APs)', fontsize=13, fontweight='bold')\nax2.set_ylabel('Alpha (Î±)', fontsize=13, fontweight='bold')\nax2.set_title('Parameter Interaction: k Ã— Î±', fontsize=13, fontweight='bold')\nax2.text(0.02, 0.98, 'B', transform=ax2.transAxes, \n         fontsize=20, fontweight='bold', va='top', color='white',\n         bbox=dict(boxstyle='round', facecolor='black', alpha=0.6))\n\n# Panel C: Violin plot of error distribution by k\nax3 = fig.add_subplot(gs[1, 0])\nk_values = sorted(phase1_df['k'].unique())\ndata_violin = [phase1_df[phase1_df['k'] == k]['mean_3d_error_m'].values for k in k_values]\nparts = ax3.violinplot(data_violin, positions=range(len(k_values)), \n                        showmeans=True, showmedians=True, widths=0.7)\n# Color the violin plots\nfor pc in parts['bodies']:\n    pc.set_facecolor('#2E86AB')\n    pc.set_alpha(0.6)\nax3.set_xticks(range(len(k_values)))\nax3.set_xticklabels(k_values)\nax3.set_xlabel('k (Number of APs)', fontsize=13, fontweight='bold')\nax3.set_ylabel('Mean 3D Error (m)', fontsize=13, fontweight='bold')\nax3.set_title('Distribution of Errors by k', fontsize=13, fontweight='bold')\nax3.grid(True, alpha=0.3, axis='y')\nax3.text(0.02, 0.98, 'C', transform=ax3.transAxes, \n         fontsize=20, fontweight='bold', va='top',\n         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n\n# Panel D: Scatter with correlation: Error vs Floor Accuracy\nax4 = fig.add_subplot(gs[1, 1])\nscatter = ax4.scatter(phase1_df['mean_3d_error_m'], \n                      phase1_df['floor_accuracy_0'] * 100,\n                      c=phase1_df['k'], cmap='viridis', \n                      s=100, alpha=0.6, edgecolors='black', linewidths=1)\n# Add regression line\nz = np.polyfit(phase1_df['mean_3d_error_m'], phase1_df['floor_accuracy_0'] * 100, 1)\np = np.poly1d(z)\nx_line = np.linspace(phase1_df['mean_3d_error_m'].min(), \n                      phase1_df['mean_3d_error_m'].max(), 100)\nax4.plot(x_line, p(x_line), \"r--\", linewidth=2, alpha=0.8, label='Trend Line')\n# Calculate correlation\ncorr = phase1_df['mean_3d_error_m'].corr(phase1_df['floor_accuracy_0'])\nax4.text(0.05, 0.95, f'Pearson r = {corr:.3f}', transform=ax4.transAxes,\n         fontsize=11, fontweight='bold', va='top',\n         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\nax4.set_xlabel('Mean 3D Error (m)', fontsize=13, fontweight='bold')\nax4.set_ylabel('Floor Accuracy (%)', fontsize=13, fontweight='bold')\nax4.set_title('Error vs Accuracy Correlation', fontsize=13, fontweight='bold')\ncbar = plt.colorbar(scatter, ax=ax4, label='k (APs)')\nax4.legend(fontsize=10)\nax4.grid(True, alpha=0.3)\nax4.text(0.02, 0.98, 'D', transform=ax4.transAxes, \n         fontsize=20, fontweight='bold', va='top',\n         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n\nplt.suptitle('Phase 1: Comprehensive QUBO Parameter Analysis', fontsize=16, fontweight='bold', y=0.995)\nplt.savefig(output_dir / 'comprehensive_phase1_analysis.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"âœ“ Comprehensive Phase 1 analysis (4-panel) saved\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Figure A: Comprehensive 4-Panel Phase 1 Analysis",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 2: OpenJij Annealing Parameter Optimization\n",
    "\n",
    "Impact of quantum annealing parameters on performance and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5: Number of Sweeps vs Time-to-Solution (TTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(10, 7))\n\n# Aggregate with error bars\ngrouped = phase2_finite.groupby('num_sweeps').agg({\n    'tts_s': ['mean', 'std', 'min', 'max']\n}).reset_index()\ngrouped.columns = ['num_sweeps', 'mean', 'std', 'min', 'max']\n\n# Plot with error bars (log scale)\nax.errorbar(grouped['num_sweeps'], grouped['mean'], yerr=grouped['std'],\n            marker='o', linewidth=3, capsize=8, capthick=2, \n            color='#2E86AB', markersize=10, label='Mean Â± Std')\n\n# Add shaded region for min/max range\nax.fill_between(grouped['num_sweeps'], grouped['min'], grouped['max'],\n                alpha=0.2, color='#2E86AB', label='Min-Max Range')\n\nax.set_xlabel('Number of Sweeps', fontsize=14, fontweight='bold')\nax.set_ylabel('Time-to-Solution (s)', fontsize=14, fontweight='bold')\nax.set_yscale('log')\nax.legend(fontsize=11, loc='best')\nax.grid(True, alpha=0.3, which='both')\n\nplt.tight_layout()\nplt.savefig(output_dir / 'sweeps_vs_tts.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"âœ“ Figure 5 saved: sweeps_vs_tts.png (with error bars)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 6: Number of Reads vs Success Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(10, 7))\n\n# Aggregate with error bars\ngrouped = phase2_finite.groupby('num_reads').agg({\n    'success_rate': ['mean', 'std', 'min', 'max']\n}).reset_index()\ngrouped.columns = ['num_reads', 'mean', 'std', 'min', 'max']\n\n# Plot with error bars\nax.errorbar(grouped['num_reads'], grouped['mean'], yerr=grouped['std'],\n            marker='s', linewidth=3, capsize=8, capthick=2, \n            color='#A23B72', markersize=10, label='Mean Â± Std')\n\n# Add shaded region for min/max range\nax.fill_between(grouped['num_reads'], grouped['min'], grouped['max'],\n                alpha=0.2, color='#A23B72', label='Min-Max Range')\n\nax.set_xlabel('Number of Reads', fontsize=14, fontweight='bold')\nax.set_ylabel('Success Rate', fontsize=14, fontweight='bold')\nax.set_ylim([0, 1.05])\nax.legend(fontsize=11, loc='best')\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(output_dir / 'reads_vs_success.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"âœ“ Figure 6 saved: reads_vs_success.png (with error bars)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7: Beta (Inverse Temperature) vs Mean 3D Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(10, 7))\n\n# Aggregate with error bars\ngrouped = phase2_finite.groupby('beta').agg({\n    'mean_3d_error_m': ['mean', 'std', 'min', 'max']\n}).reset_index()\ngrouped.columns = ['beta', 'mean', 'std', 'min', 'max']\n\n# Plot with error bars\nax.errorbar(grouped['beta'], grouped['mean'], yerr=grouped['std'],\n            marker='D', linewidth=3, capsize=8, capthick=2, \n            color='#F18F01', markersize=10, label='Mean Â± Std')\n\n# Add shaded region for min/max range\nax.fill_between(grouped['beta'], grouped['min'], grouped['max'],\n                alpha=0.2, color='#F18F01', label='Min-Max Range')\n\nax.set_xlabel('Beta (Î²) - Inverse Temperature', fontsize=14, fontweight='bold')\nax.set_ylabel('Mean 3D Error (m)', fontsize=14, fontweight='bold')\nax.legend(fontsize=11, loc='best')\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(output_dir / 'beta_vs_error.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"âœ“ Figure 7 saved: beta_vs_error.png (with error bars)\")"
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# PHASE 2 PARAMETER INTERACTION HEATMAPS (6-PANEL)\n# ============================================================================\n\nfig, axes = plt.subplots(2, 3, figsize=(18, 12))\n\n# Heatmap 1: TTS (sweeps vs reads)\npivot1 = phase2_finite.pivot_table(values='tts_s', index='num_reads', \n                                    columns='num_sweeps', aggfunc='mean')\nsns.heatmap(pivot1, annot=True, fmt='.3f', cmap='YlOrRd', ax=axes[0, 0],\n            cbar_kws={'label': 'TTS (s)'})\naxes[0, 0].set_title('TTS: Sweeps Ã— Reads', fontsize=14, fontweight='bold')\naxes[0, 0].set_xlabel('Number of Sweeps', fontsize=12, fontweight='bold')\naxes[0, 0].set_ylabel('Number of Reads', fontsize=12, fontweight='bold')\n\n# Heatmap 2: Success Rate (beta vs gamma)\npivot2 = phase2_finite.pivot_table(values='success_rate', index='gamma', \n                                    columns='beta', aggfunc='mean')\nsns.heatmap(pivot2, annot=True, fmt='.2f', cmap='RdYlGn', ax=axes[0, 1],\n            cbar_kws={'label': 'Success Rate'}, vmin=0, vmax=1)\naxes[0, 1].set_title('Success Rate: Beta Ã— Gamma', fontsize=14, fontweight='bold')\naxes[0, 1].set_xlabel('Beta (Î²)', fontsize=12, fontweight='bold')\naxes[0, 1].set_ylabel('Gamma (Î³)', fontsize=12, fontweight='bold')\n\n# Heatmap 3: Mean 3D Error (beta vs gamma)\npivot3 = phase2_finite.pivot_table(values='mean_3d_error_m', index='gamma', \n                                    columns='beta', aggfunc='mean')\nsns.heatmap(pivot3, annot=True, fmt='.1f', cmap='RdYlGn_r', ax=axes[0, 2],\n            cbar_kws={'label': 'Mean 3D Error (m)'})\naxes[0, 2].set_title('Positioning Error: Beta Ã— Gamma', fontsize=14, fontweight='bold')\naxes[0, 2].set_xlabel('Beta (Î²)', fontsize=12, fontweight='bold')\naxes[0, 2].set_ylabel('Gamma (Î³)', fontsize=12, fontweight='bold')\n\n# Heatmap 4: Floor Accuracy (sweeps vs reads)\npivot4 = phase2_finite.pivot_table(values='floor_accuracy_0', index='num_reads', \n                                    columns='num_sweeps', aggfunc='mean')\nsns.heatmap(pivot4, annot=True, fmt='.2f', cmap='Blues', ax=axes[1, 0],\n            cbar_kws={'label': 'Floor Accuracy'})\naxes[1, 0].set_title('Floor Accuracy: Sweeps Ã— Reads', fontsize=14, fontweight='bold')\naxes[1, 0].set_xlabel('Number of Sweeps', fontsize=12, fontweight='bold')\naxes[1, 0].set_ylabel('Number of Reads', fontsize=12, fontweight='bold')\n\n# Heatmap 5: Correlation matrix\ncorr_cols = ['num_sweeps', 'num_reads', 'beta', 'gamma', 'tts_s', \n             'success_rate', 'mean_3d_error_m', 'floor_accuracy_0']\ncorr_matrix = phase2_finite[corr_cols].corr()\nsns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n            center=0, ax=axes[1, 1], vmin=-1, vmax=1,\n            cbar_kws={'label': 'Correlation'})\naxes[1, 1].set_title('Parameter Correlation Matrix', fontsize=14, fontweight='bold')\naxes[1, 1].set_xticklabels(axes[1, 1].get_xticklabels(), rotation=45, ha='right')\naxes[1, 1].set_yticklabels(axes[1, 1].get_yticklabels(), rotation=0)\n\n# Heatmap 6: TTS (beta vs gamma)\npivot6 = phase2_finite.pivot_table(values='tts_s', index='gamma', \n                                    columns='beta', aggfunc='mean')\nsns.heatmap(pivot6, annot=True, fmt='.2f', cmap='YlOrRd', ax=axes[1, 2],\n            cbar_kws={'label': 'TTS (s)'})\naxes[1, 2].set_title('TTS: Beta Ã— Gamma', fontsize=14, fontweight='bold')\naxes[1, 2].set_xlabel('Beta (Î²)', fontsize=12, fontweight='bold')\naxes[1, 2].set_ylabel('Gamma (Î³)', fontsize=12, fontweight='bold')\n\nplt.suptitle('Phase 2: Parameter Interaction Analysis', fontsize=16, fontweight='bold')\nplt.tight_layout()\nplt.savefig(output_dir / 'phase2_parameter_interactions.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"âœ“ Phase 2 parameter interaction heatmaps (6-panel) saved\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Figure B: Phase 2 Parameter Interaction Heatmaps (6-Panel)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 8: Gamma (Transverse Field) vs Floor Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(10, 7))\n\n# Aggregate with error bars\ngrouped = phase2_finite.groupby('gamma').agg({\n    'floor_accuracy_0': ['mean', 'std', 'min', 'max']\n}).reset_index()\ngrouped.columns = ['gamma', 'mean', 'std', 'min', 'max']\ngrouped['mean_pct'] = grouped['mean'] * 100\ngrouped['std_pct'] = grouped['std'] * 100\ngrouped['min_pct'] = grouped['min'] * 100\ngrouped['max_pct'] = grouped['max'] * 100\n\n# Plot with error bars\nax.errorbar(grouped['gamma'], grouped['mean_pct'], yerr=grouped['std_pct'],\n            marker='^', linewidth=3, capsize=8, capthick=2, \n            color='#C73E1D', markersize=10, label='Mean Â± Std')\n\n# Add shaded region for min/max range\nax.fill_between(grouped['gamma'], grouped['min_pct'], grouped['max_pct'],\n                alpha=0.2, color='#C73E1D', label='Min-Max Range')\n\nax.set_xlabel('Gamma (Î³) - Transverse Field', fontsize=14, fontweight='bold')\nax.set_ylabel('Floor Accuracy (%)', fontsize=14, fontweight='bold')\nax.legend(fontsize=11, loc='best')\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(output_dir / 'gamma_vs_floor_acc.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"âœ“ Figure 8 saved: gamma_vs_floor_acc.png (with error bars)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Importance Metrics Comparison\n",
    "\n",
    "Comparison of AP selection methods for k=20."
   ]
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# PARETO FRONT ANALYSIS (MULTI-OBJECTIVE OPTIMIZATION)\n# ============================================================================\n\ndef is_pareto_optimal(costs):\n    \"\"\"\n    Find Pareto optimal points for minimizing x and maximizing y.\n    costs: Nx2 array where column 0 should be minimized and column 1 maximized\n    \"\"\"\n    is_optimal = np.ones(costs.shape[0], dtype=bool)\n    for i in range(len(costs)):\n        # Check if any other point dominates this one\n        # A point j dominates i if: cost0[j] < cost0[i] AND cost1[j] > cost1[i]\n        dominated = np.any(\n            (costs[:, 0] < costs[i, 0]) & (costs[:, 1] > costs[i, 1])\n        )\n        is_optimal[i] = not dominated\n    return is_optimal\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 7))\n\n# ============================================================================\n# Left Panel: Phase 2 Pareto Front (TTS vs Floor Accuracy)\n# ============================================================================\nax1 = axes[0]\n\ncosts = phase2_finite[['tts_s', 'floor_accuracy_0']].values\npareto_mask = is_pareto_optimal(costs)\n\n# Plot all points\nax1.scatter(phase2_finite['tts_s'], phase2_finite['floor_accuracy_0'] * 100,\n           alpha=0.4, s=100, color='lightblue', edgecolors='black', linewidths=0.5,\n           label=f'All Configurations ({len(phase2_finite)})')\n\n# Highlight Pareto optimal points\npareto_points = phase2_finite[pareto_mask].sort_values('tts_s')\nax1.scatter(pareto_points['tts_s'], pareto_points['floor_accuracy_0'] * 100,\n           s=300, color='red', marker='*', edgecolors='darkred', linewidths=2,\n           label=f'Pareto Optimal ({pareto_mask.sum()})', zorder=10)\n\n# Connect Pareto front\nax1.plot(pareto_points['tts_s'], pareto_points['floor_accuracy_0'] * 100,\n        'r--', linewidth=2, alpha=0.7, zorder=5, label='Pareto Front')\n\n# Annotate some key Pareto points\nfor idx, row in pareto_points.head(3).iterrows():\n    ax1.annotate(f\"TTS={row['tts_s']:.3f}s\\nAcc={row['floor_accuracy_0']*100:.1f}%\",\n                xy=(row['tts_s'], row['floor_accuracy_0'] * 100),\n                xytext=(10, 10), textcoords='offset points',\n                fontsize=8, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7),\n                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n\nax1.set_xlabel('Time-to-Solution (s)', fontsize=14, fontweight='bold')\nax1.set_ylabel('Floor Accuracy (%)', fontsize=14, fontweight='bold')\nax1.set_xscale('log')\nax1.legend(fontsize=11, loc='best')\nax1.grid(True, alpha=0.3)\nax1.set_title('Phase 2: TTS vs Accuracy Trade-off', fontsize=14, fontweight='bold')\n\n# Add text box with Pareto summary\ntextstr = f'Pareto Optimal: {pareto_mask.sum()}/{len(phase2_finite)}\\n({pareto_mask.sum()/len(phase2_finite)*100:.1f}% of configs)'\nprops = dict(boxstyle='round', facecolor='lightgreen', alpha=0.8)\nax1.text(0.05, 0.05, textstr, transform=ax1.transAxes, fontsize=11,\n        verticalalignment='bottom', bbox=props)\n\n# ============================================================================\n# Right Panel: Phase 1 Pareto Front (Error vs Floor Accuracy)\n# ============================================================================\nax2 = axes[1]\n\ncosts2 = phase1_df[['mean_3d_error_m', 'floor_accuracy_0']].values\npareto_mask2 = is_pareto_optimal(costs2)\n\n# Plot all points colored by k\nscatter = ax2.scatter(phase1_df['mean_3d_error_m'], phase1_df['floor_accuracy_0'] * 100,\n           alpha=0.5, s=100, c=phase1_df['k'], cmap='viridis', \n           edgecolors='black', linewidths=0.5,\n           label=f'All Configurations ({len(phase1_df)})')\n\n# Highlight Pareto optimal points\npareto_points2 = phase1_df[pareto_mask2].sort_values('mean_3d_error_m')\nax2.scatter(pareto_points2['mean_3d_error_m'], pareto_points2['floor_accuracy_0'] * 100,\n           s=300, color='darkgreen', marker='*', edgecolors='green', linewidths=2,\n           label=f'Pareto Optimal ({pareto_mask2.sum()})', zorder=10)\n\n# Connect Pareto front\nax2.plot(pareto_points2['mean_3d_error_m'], pareto_points2['floor_accuracy_0'] * 100,\n        'g--', linewidth=2, alpha=0.7, zorder=5, label='Pareto Front')\n\n# Annotate best Pareto point\nbest_pareto = pareto_points2.iloc[0]\nax2.annotate(f\"Best: k={int(best_pareto['k'])}\\nError={best_pareto['mean_3d_error_m']:.2f}m\\nAcc={best_pareto['floor_accuracy_0']*100:.1f}%\",\n            xy=(best_pareto['mean_3d_error_m'], best_pareto['floor_accuracy_0'] * 100),\n            xytext=(15, 15), textcoords='offset points',\n            fontsize=9, fontweight='bold',\n            bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8),\n            arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0.3', lw=2))\n\nax2.set_xlabel('Mean 3D Error (m)', fontsize=14, fontweight='bold')\nax2.set_ylabel('Floor Accuracy (%)', fontsize=14, fontweight='bold')\nax2.legend(fontsize=11, loc='best')\ncbar = plt.colorbar(scatter, ax=ax2, label='k (Number of APs)')\nax2.grid(True, alpha=0.3)\nax2.set_title('Phase 1: Error vs Accuracy Trade-off', fontsize=14, fontweight='bold')\n\n# Add text box with Pareto summary\ntextstr2 = f'Pareto Optimal: {pareto_mask2.sum()}/{len(phase1_df)}\\n({pareto_mask2.sum()/len(phase1_df)*100:.1f}% of configs)'\nprops2 = dict(boxstyle='round', facecolor='lightgreen', alpha=0.8)\nax2.text(0.05, 0.05, textstr2, transform=ax2.transAxes, fontsize=11,\n        verticalalignment='bottom', bbox=props2)\n\nplt.tight_layout()\nplt.savefig(output_dir / 'pareto_front_analysis.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"âœ“ Pareto front analysis saved\")\nprint(f\"  Phase 2 Pareto optimal configurations: {pareto_mask.sum()}/{len(phase2_finite)}\")\nprint(f\"  Phase 1 Pareto optimal configurations: {pareto_mask2.sum()}/{len(phase1_df)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Figure D: Pareto Front Analysis (Multi-Objective Optimization)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# STATISTICAL COMPARISON WITH SIGNIFICANCE ANNOTATIONS\n# ============================================================================\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 7))\n\n# Left panel: Error comparison with significance\nax1 = axes[0]\nmethods = k20_df['Importance_Method'].tolist()\nerrors = k20_df['Median_3D_Error_m'].tolist()\ncolors_stat = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6A4C93'][:len(methods)]\n\nbars = ax1.bar(methods, errors, color=colors_stat, edgecolor='black', \n               linewidth=2, alpha=0.8)\n\n# Add value labels\nfor bar in bars:\n    height = bar.get_height()\n    ax1.text(bar.get_x() + bar.get_width()/2., height,\n            f'{height:.2f}m',\n            ha='center', va='bottom', fontsize=11, fontweight='bold')\n\n# Add statistical annotations (best vs others)\nbest_idx = np.argmin(errors)\ny_offset = 0.5\nfor i in range(len(errors)):\n    if i != best_idx:\n        improvement = ((errors[i] - errors[best_idx]) / errors[i]) * 100\n        y_pos = max(errors[i], errors[best_idx]) + y_offset\n        ax1.plot([best_idx, i], [y_pos, y_pos], 'k-', linewidth=1.5)\n        ax1.text((best_idx + i) / 2, y_pos + 0.2, \n                f'{improvement:.1f}% worse',\n                ha='center', fontsize=9, fontweight='bold',\n                bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n        y_offset += 0.8\n\nax1.set_xlabel('Importance Method', fontsize=14, fontweight='bold')\nax1.set_ylabel('Median 3D Error (m)', fontsize=14, fontweight='bold')\nax1.set_title('Performance Comparison (Lower is Better)', fontsize=14, fontweight='bold')\nax1.grid(True, alpha=0.3, axis='y')\nax1.set_ylim(0, max(errors) * 1.4)\n\n# Highlight best method\nbest_bar = bars[best_idx]\nbest_bar.set_edgecolor('green')\nbest_bar.set_linewidth(4)\nax1.text(best_bar.get_x() + best_bar.get_width()/2., -0.5,\n        'â˜… BEST â˜…', ha='center', fontsize=11, fontweight='bold', color='green')\n\n# Right panel: Multi-metric comparison (normalized)\nax2 = axes[1]\nx = np.arange(len(methods))\nwidth = 0.25\n\nmetrics_dict = {\n    'Median Error': k20_df['Median_3D_Error_m'].tolist(),\n    'Floor Acc (%)': k20_df['Floor_Accuracy_Exact_Pct'].tolist(),\n    'Mean Error': k20_df['Mean_3D_Error_m'].tolist()\n}\n\n# Normalize for comparison (0-100 scale, higher is better)\nnormalized = {}\nfor key, values in metrics_dict.items():\n    if 'Error' in key:\n        # Lower is better - invert and normalize\n        normalized[key] = [100 * (max(values) - v) / (max(values) - min(values)) if max(values) != min(values) else 50 for v in values]\n    else:\n        # Higher is better - normalize as is\n        normalized[key] = [(v - min(values)) / (max(values) - min(values)) * 100 if max(values) != min(values) else 50 for v in values]\n\nbar_colors = ['#2E86AB', '#A23B72', '#F18F01']\nfor i, (key, values) in enumerate(normalized.items()):\n    offset = (i - 1) * width\n    ax2.bar(x + offset, values, width, label=key, alpha=0.8, \n            edgecolor='black', color=bar_colors[i])\n\nax2.set_xlabel('Importance Method', fontsize=14, fontweight='bold')\nax2.set_ylabel('Normalized Score (0-100, higher=better)', fontsize=14, fontweight='bold')\nax2.set_title('Multi-Metric Performance (Normalized)', fontsize=14, fontweight='bold')\nax2.set_xticks(x)\nax2.set_xticklabels(methods, rotation=15, ha='right')\nax2.legend(fontsize=11, loc='best')\nax2.grid(True, alpha=0.3, axis='y')\nax2.set_ylim([0, 105])\n\nplt.tight_layout()\nplt.savefig(output_dir / 'importance_statistical_comparison.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"âœ“ Statistical comparison with significance annotations saved\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Figure C: Statistical Comparison with Significance Annotations",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 9: Importance Method vs Median 3D Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D']\n",
    "bars = ax.bar(k20_df['Importance_Method'], k20_df['Median_3D_Error_m'], \n",
    "              color=colors, edgecolor='black', linewidth=2, alpha=0.8)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.2f}',\n",
    "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Importance Method', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Median 3D Error (m)', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'method_vs_error.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Figure 9 saved: method_vs_error.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 10: Importance Method vs Floor Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D']\n",
    "bars = ax.bar(k20_df['Importance_Method'], k20_df['Floor_Accuracy_Exact_Pct'], \n",
    "              color=colors, edgecolor='black', linewidth=2, alpha=0.8)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Importance Method', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Floor Accuracy (%)', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'method_vs_floor_acc.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Figure 10 saved: method_vs_floor_acc.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*80)\nprint(\"PAPER VISUALIZATION GENERATION COMPLETE\")\nprint(\"=\"*80)\nprint(f\"\\nAll figures saved to: {output_dir}\")\nprint(f\"  Resolution: 300 DPI\")\nprint(f\"  Format: PNG (publication-ready)\")\nprint(\"\\n\" + \"=\"*80)\nprint(\"VISUALIZATION SUMMARY\")\nprint(\"=\"*80)\nprint(\"\\nðŸ“Š BASIC FIGURES (with Error Bars & Confidence Intervals):\")\nprint(\"  âœ“ Figure 1: k vs Mean 3D Error\")\nprint(\"  âœ“ Figure 2: k vs Floor Accuracy\")\nprint(\"  âœ“ Figure 3: Alpha vs Mean 3D Error\")\nprint(\"  âœ“ Figure 4: Penalty vs Floor Accuracy\")\nprint(\"  âœ“ Figure 5: Sweeps vs Time-to-Solution (TTS)\")\nprint(\"  âœ“ Figure 6: Reads vs Success Rate\")\nprint(\"  âœ“ Figure 7: Beta vs Mean 3D Error\")\nprint(\"  âœ“ Figure 8: Gamma vs Floor Accuracy\")\nprint(\"  âœ“ Figure 9: Importance Method vs Median Error\")\nprint(\"  âœ“ Figure 10: Importance Method vs Floor Accuracy\")\nprint(\"\\nðŸ“ˆ ADVANCED COMPREHENSIVE FIGURES:\")\nprint(\"  âœ“ Figure A: Comprehensive 4-Panel Phase 1 Analysis\")\nprint(\"     - Error trends with uncertainty\")\nprint(\"     - Parameter interaction heatmap (k Ã— Î±)\")\nprint(\"     - Error distribution violin plots\")\nprint(\"     - Error vs Accuracy correlation\")\nprint(\"\\nðŸ”¥ ADVANCED HEATMAP ANALYSIS:\")\nprint(\"  âœ“ Figure B: Phase 2 Parameter Interaction (6-Panel)\")\nprint(\"     - TTS: Sweeps Ã— Reads\")\nprint(\"     - Success Rate: Beta Ã— Gamma\")\nprint(\"     - Positioning Error: Beta Ã— Gamma\")\nprint(\"     - Floor Accuracy: Sweeps Ã— Reads\")\nprint(\"     - Full correlation matrix\")\nprint(\"     - TTS: Beta Ã— Gamma\")\nprint(\"\\nðŸ“Š STATISTICAL ANALYSIS:\")\nprint(\"  âœ“ Figure C: Statistical Comparison (2-Panel)\")\nprint(\"     - Performance comparison with significance annotations\")\nprint(\"     - Multi-metric normalized comparison\")\nprint(\"\\nâš¡ PARETO FRONT ANALYSIS:\")\nprint(\"  âœ“ Figure D: Multi-Objective Optimization (2-Panel)\")\nprint(\"     - Phase 2: TTS vs Accuracy trade-off\")\nprint(\"     - Phase 1: Error vs Accuracy trade-off\")\nprint(\"\\n\" + \"=\"*80)\nprint(f\"TOTAL: 18 publication-ready figures generated\")\nprint(\"  - 10 Basic parameter analysis figures (with error bars)\")\nprint(\"  - 4 Comprehensive multi-panel figures\")\nprint(\"  - 4 Advanced analysis figures\")\nprint(\"=\"*80)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}