{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Annealing Time Analysis: SA vs SQA\n",
    "\n",
    "This notebook provides a **comprehensive annealing time comparison** using proper methodologies for both SA and SQA.\n",
    "\n",
    "## Annealing Time Calculation Methods:\n",
    "\n",
    "### **1. SQA (OpenJij) - Based on OpenJij Tutorial:**\n",
    "- **Execution Time**: From `response.info['execution_time']`\n",
    "- **Annealing Time**: Proportional to `num_sweeps` (Monte Carlo steps)\n",
    "- **TTS Formula**: `TTS = τ × [ln(1 - p_R) / ln(1 - p_s)]`\n",
    "\n",
    "### **2. SA (D-Wave) - Based on SA Literature:**\n",
    "- **Annealing Time**: Based on cooling schedule and sweeps per temperature\n",
    "- **Total Time**: `T_anneal = num_sweeps × time_per_sweep`\n",
    "- **Cooling Schedule**: Geometric cooling with `beta_range = (β_min, β_max)`\n",
    "\n",
    "## Key Metrics:\n",
    "1. **Raw Execution Time**: Wall-clock time for solver\n",
    "2. **Annealing Time**: Pure optimization time (no overhead)\n",
    "3. **Success Probability**: Quality-based success rate\n",
    "4. **Time-to-Solution (TTS)**: Fair comparison metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "print(f\"✓ Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import openjij as oj\n",
    "from dwave.samplers import SimulatedAnnealingSampler\n",
    "import dimod\n",
    "import warnings\n",
    "\n",
    "from scripts.data.data_loaders import load_all_precomputed_data\n",
    "from scripts.optimization.QUBO import formulate_qubo\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting configuration\n",
    "SCALE_FACTOR = 1.8\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = int(12 * SCALE_FACTOR)\n",
    "plt.rcParams['axes.linewidth'] = 2 * SCALE_FACTOR\n",
    "plt.rcParams['lines.linewidth'] = 3 * SCALE_FACTOR\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"✓ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "output_dir = project_root / 'data' / 'results' / 'visualizations' / 'paper'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "importance_dicts, redundancy_matrix = load_all_precomputed_data()\n",
    "importance_method = importance_dicts['entropy']\n",
    "\n",
    "# QUBO parameters\n",
    "k = 20\n",
    "alpha = 0.9\n",
    "penalty = 2.0\n",
    "\n",
    "# Annealing parameters\n",
    "num_sweeps_values = [100, 500, 1000, 2000, 5000]\n",
    "num_reads_fixed = 100\n",
    "num_repetitions = 10\n",
    "p_target = 0.99\n",
    "\n",
    "# SA cooling schedule\n",
    "beta_range = (0.1, 5.0)  # Inverse temperature range\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPLETE ANNEALING TIME ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"QUBO: k={k}, alpha={alpha}, penalty={penalty}\")\n",
    "print(f\"Sweep values: {num_sweeps_values}\")\n",
    "print(f\"Fixed num_reads: {num_reads_fixed}\")\n",
    "print(f\"Repetitions: {num_repetitions}\")\n",
    "print(f\"SA beta_range: {beta_range}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulate QUBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, relevant_aps, offset = formulate_qubo(importance_method, redundancy_matrix, k, alpha, penalty)\n",
    "print(f\"✓ QUBO formulated: {len(relevant_aps)} APs, {len(Q)} terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tts(execution_time, success_prob, p_target=0.99):\n",
    "    \"\"\"Calculate Time-to-Solution (TTS).\"\"\"\n",
    "    if success_prob <= 0 or success_prob >= 1:\n",
    "        return np.inf\n",
    "    return execution_time * (np.log(1 - p_target) / np.log(1 - success_prob))\n",
    "\n",
    "def estimate_sa_annealing_time(num_sweeps, num_reads, beta_range):\n",
    "    \"\"\"\n",
    "    Estimate SA annealing time based on cooling schedule.\n",
    "    \n",
    "    For geometric cooling schedule:\n",
    "    - Time per sweep ≈ 1e-6 seconds (typical for small QUBO)\n",
    "    - Total sweeps = num_sweeps × num_reads\n",
    "    - Annealing time = total_sweeps × time_per_sweep\n",
    "    \"\"\"\n",
    "    time_per_sweep = 1e-6  # Estimated time per sweep in seconds\n",
    "    total_sweeps = num_sweeps * num_reads\n",
    "    return total_sweeps * time_per_sweep\n",
    "\n",
    "def get_best_energy(Q, method='openjij', trials=50):\n",
    "    \"\"\"Find best known energy.\"\"\"\n",
    "    best_energy = np.inf\n",
    "    \n",
    "    if method == 'openjij':\n",
    "        sampler = oj.SQASampler()\n",
    "        for _ in range(trials):\n",
    "            response = sampler.sample_qubo(Q, num_reads=100, num_sweeps=5000)\n",
    "            best_energy = min(best_energy, response.first.energy)\n",
    "    else:  # D-Wave SA\n",
    "        bqm = dimod.BinaryQuadraticModel(Q, 'BINARY')\n",
    "        sampler = SimulatedAnnealingSampler()\n",
    "        for _ in range(trials):\n",
    "            response = sampler.sample(bqm, num_reads=100, num_sweeps=5000, beta_range=beta_range)\n",
    "            best_energy = min(best_energy, response.first.energy)\n",
    "    \n",
    "    return best_energy\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Best Known Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finding best known energy...\")\n",
    "best_energy_sqa = get_best_energy(Q, method='openjij', trials=30)\n",
    "best_energy_sa = get_best_energy(Q, method='dwave', trials=30)\n",
    "best_known_energy = min(best_energy_sqa, best_energy_sa)\n",
    "energy_tolerance = abs(best_known_energy) * 0.01  # 1% tolerance\n",
    "\n",
    "print(f\"✓ Best energy from SQA: {best_energy_sqa:.4f}\")\n",
    "print(f\"✓ Best energy from SA: {best_energy_sa:.4f}\")\n",
    "print(f\"✓ Best known energy: {best_known_energy:.4f}\")\n",
    "print(f\"✓ Success tolerance: ±{energy_tolerance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark: SQA (OpenJij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BENCHMARKING SQA (OpenJij)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sqa_results = []\n",
    "\n",
    "for num_sweeps in num_sweeps_values:\n",
    "    print(f\"\\nTesting num_sweeps={num_sweeps}...\")\n",
    "    \n",
    "    wall_times = []\n",
    "    exec_times = []\n",
    "    successes = 0\n",
    "    energies = []\n",
    "    \n",
    "    for rep in range(num_repetitions):\n",
    "        # Measure wall-clock time\n",
    "        wall_start = time.time()\n",
    "        \n",
    "        sampler = oj.SQASampler()\n",
    "        response = sampler.sample_qubo(Q, num_reads=num_reads_fixed, num_sweeps=num_sweeps)\n",
    "        \n",
    "        wall_end = time.time()\n",
    "        \n",
    "        # Get OpenJij's internal execution time\n",
    "        exec_time = response.info.get('execution_time', wall_end - wall_start)\n",
    "        \n",
    "        wall_times.append(wall_end - wall_start)\n",
    "        exec_times.append(exec_time)\n",
    "        energies.append(response.first.energy)\n",
    "        \n",
    "        # Check success\n",
    "        if abs(response.first.energy - best_known_energy) <= energy_tolerance:\n",
    "            successes += 1\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_wall_time = np.mean(wall_times)\n",
    "    avg_exec_time = np.mean(exec_times)\n",
    "    estimated_annealing_time = num_sweeps * num_reads_fixed * 1e-6\n",
    "    success_prob = successes / num_repetitions\n",
    "    tts = calculate_tts(avg_exec_time, success_prob, p_target)\n",
    "    avg_energy = np.mean(energies)\n",
    "    \n",
    "    sqa_results.append({\n",
    "        'Method': 'SQA',\n",
    "        'num_sweeps': num_sweeps,\n",
    "        'num_reads': num_reads_fixed,\n",
    "        'avg_wall_time': avg_wall_time,\n",
    "        'std_wall_time': np.std(wall_times),\n",
    "        'avg_exec_time': avg_exec_time,\n",
    "        'std_exec_time': np.std(exec_times),\n",
    "        'estimated_annealing_time': estimated_annealing_time,\n",
    "        'overhead_time': avg_wall_time - estimated_annealing_time,\n",
    "        'success_prob': success_prob,\n",
    "        'tts': tts,\n",
    "        'avg_energy': avg_energy,\n",
    "        'successes': successes\n",
    "    })\n",
    "    \n",
    "    print(f\"  Wall time: {avg_wall_time:.6f}s\")\n",
    "    print(f\"  Exec time: {avg_exec_time:.6f}s\")\n",
    "    print(f\"  Annealing time: {estimated_annealing_time:.6f}s\")\n",
    "    print(f\"  Success: {success_prob:.2%} ({successes}/{num_repetitions})\")\n",
    "    print(f\"  TTS: {tts:.6f}s\")\n",
    "\n",
    "df_sqa = pd.DataFrame(sqa_results)\n",
    "print(f\"\\n✓ SQA benchmarking complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark: SA (D-Wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BENCHMARKING SA (D-Wave)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sa_results = []\n",
    "\n",
    "for num_sweeps in num_sweeps_values:\n",
    "    print(f\"\\nTesting num_sweeps={num_sweeps}...\")\n",
    "    \n",
    "    wall_times = []\n",
    "    successes = 0\n",
    "    energies = []\n",
    "    \n",
    "    for rep in range(num_repetitions):\n",
    "        bqm = dimod.BinaryQuadraticModel(Q, 'BINARY')\n",
    "        sampler = SimulatedAnnealingSampler()\n",
    "        \n",
    "        # Measure wall-clock time\n",
    "        wall_start = time.time()\n",
    "        response = sampler.sample(bqm, num_reads=num_reads_fixed, num_sweeps=num_sweeps, beta_range=beta_range)\n",
    "        wall_end = time.time()\n",
    "        \n",
    "        wall_times.append(wall_end - wall_start)\n",
    "        energies.append(response.first.energy)\n",
    "        \n",
    "        # Check success\n",
    "        if abs(response.first.energy - best_known_energy) <= energy_tolerance:\n",
    "            successes += 1\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_wall_time = np.mean(wall_times)\n",
    "    estimated_annealing_time = estimate_sa_annealing_time(num_sweeps, num_reads_fixed, beta_range)\n",
    "    success_prob = successes / num_repetitions\n",
    "    tts = calculate_tts(avg_wall_time, success_prob, p_target)\n",
    "    avg_energy = np.mean(energies)\n",
    "    \n",
    "    sa_results.append({\n",
    "        'Method': 'SA',\n",
    "        'num_sweeps': num_sweeps,\n",
    "        'num_reads': num_reads_fixed,\n",
    "        'avg_wall_time': avg_wall_time,\n",
    "        'std_wall_time': np.std(wall_times),\n",
    "        'avg_exec_time': avg_wall_time,  # SA doesn't provide separate exec time\n",
    "        'std_exec_time': np.std(wall_times),\n",
    "        'estimated_annealing_time': estimated_annealing_time,\n",
    "        'overhead_time': avg_wall_time - estimated_annealing_time,\n",
    "        'success_prob': success_prob,\n",
    "        'tts': tts,\n",
    "        'avg_energy': avg_energy,\n",
    "        'successes': successes\n",
    "    })\n",
    "    \n",
    "    print(f\"  Wall time: {avg_wall_time:.6f}s\")\n",
    "    print(f\"  Annealing time: {estimated_annealing_time:.6f}s\")\n",
    "    print(f\"  Success: {success_prob:.2%} ({successes}/{num_repetitions})\")\n",
    "    print(f\"  TTS: {tts:.6f}s\")\n",
    "\n",
    "df_sa = pd.DataFrame(sa_results)\n",
    "print(f\"\\n✓ SA benchmarking complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df_sqa, df_sa], ignore_index=True)\n",
    "print(\"✓ Results combined\")\n",
    "print(f\"\\nTotal experiments: {len(df_combined)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 1: Annealing Time Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Plot 1: Wall Time vs Estimated Annealing Time\n",
    "for method in ['SQA', 'SA']:\n",
    "    data = df_combined[df_combined['Method'] == method]\n",
    "    axes[0].errorbar(data['num_sweeps'], data['avg_wall_time'],\n",
    "                    yerr=data['std_wall_time'],\n",
    "                    marker='o', markersize=8, linewidth=2.5, capsize=5,\n",
    "                    label=f'{method} Wall Time')\n",
    "    axes[0].plot(data['num_sweeps'], data['estimated_annealing_time'],\n",
    "                marker='s', markersize=6, linewidth=2, linestyle='--',\n",
    "                label=f'{method} Annealing Time')\n",
    "\n",
    "axes[0].set_xlabel('Number of Sweeps', fontsize=18, fontweight='bold')\n",
    "axes[0].set_ylabel('Time (seconds)', fontsize=18, fontweight='bold')\n",
    "axes[0].set_title('Wall Time vs Annealing Time', fontsize=20, fontweight='bold', pad=20)\n",
    "axes[0].legend(fontsize=14, loc='upper left')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Plot 2: Overhead Time\n",
    "for method in ['SQA', 'SA']:\n",
    "    data = df_combined[df_combined['Method'] == method]\n",
    "    axes[1].plot(data['num_sweeps'], data['overhead_time'],\n",
    "                marker='o', markersize=8, linewidth=2.5,\n",
    "                label=method)\n",
    "\n",
    "axes[1].set_xlabel('Number of Sweeps', fontsize=18, fontweight='bold')\n",
    "axes[1].set_ylabel('Overhead Time (seconds)', fontsize=18, fontweight='bold')\n",
    "axes[1].set_title('Implementation Overhead', fontsize=20, fontweight='bold', pad=20)\n",
    "axes[1].legend(fontsize=16)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'complete_annealing_time_breakdown.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 1 saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 2: Time-to-Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Plot 1: Success Probability\n",
    "for method in ['SQA', 'SA']:\n",
    "    data = df_combined[df_combined['Method'] == method]\n",
    "    axes[0].plot(data['num_sweeps'], data['success_prob'] * 100,\n",
    "                marker='o', markersize=8, linewidth=2.5,\n",
    "                label=method)\n",
    "\n",
    "axes[0].set_xlabel('Number of Sweeps', fontsize=18, fontweight='bold')\n",
    "axes[0].set_ylabel('Success Probability (%)', fontsize=18, fontweight='bold')\n",
    "axes[0].set_title('Success Probability vs num_sweeps', fontsize=20, fontweight='bold', pad=20)\n",
    "axes[0].legend(fontsize=16)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xscale('log')\n",
    "\n",
    "# Plot 2: Time-to-Solution\n",
    "for method in ['SQA', 'SA']:\n",
    "    data = df_combined[df_combined['Method'] == method]\n",
    "    data_finite = data[data['tts'] != np.inf]\n",
    "    if len(data_finite) > 0:\n",
    "        axes[1].plot(data_finite['num_sweeps'], data_finite['tts'],\n",
    "                    marker='o', markersize=10, linewidth=3,\n",
    "                    label=method)\n",
    "\n",
    "axes[1].set_xlabel('Number of Sweeps', fontsize=18, fontweight='bold')\n",
    "axes[1].set_ylabel(f'TTS (seconds, p={p_target})', fontsize=18, fontweight='bold')\n",
    "axes[1].set_title('Time-to-Solution Comparison', fontsize=20, fontweight='bold', pad=20)\n",
    "axes[1].legend(fontsize=16)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'complete_annealing_tts.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 2 saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPLETE ANNEALING TIME ANALYSIS - SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nBest Known Energy: {best_known_energy:.4f}\")\n",
    "print(f\"Success Tolerance: ±{energy_tolerance:.4f} (1%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SQA (OpenJij) Results:\")\n",
    "print(\"=\"*80)\n",
    "print(df_sqa[['num_sweeps', 'avg_wall_time', 'estimated_annealing_time', \n",
    "              'overhead_time', 'success_prob', 'tts']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SA (D-Wave) Results:\")\n",
    "print(\"=\"*80)\n",
    "print(df_sa[['num_sweeps', 'avg_wall_time', 'estimated_annealing_time', \n",
    "             'overhead_time', 'success_prob', 'tts']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"1. Annealing Time Calculation:\")\n",
    "print(\"   - SQA: From response.info['execution_time'] (OpenJij standard)\")\n",
    "print(\"   - SA: Estimated as num_sweeps × num_reads × time_per_sweep\")\n",
    "print(\"\\n2. Overhead Analysis:\")\n",
    "print(\"   - Overhead = Wall Time - Annealing Time\")\n",
    "print(\"   - Shows framework-specific computational costs\")\n",
    "print(\"\\n3. Time-to-Solution (TTS):\")\n",
    "print(\"   - Accounts for both speed AND quality\")\n",
    "print(\"   - Fair comparison metric between methods\")\n",
    "print(\"   - Lower TTS = better overall performance\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = project_root / 'data' / 'results' / 'complete_annealing_time_analysis.xlsx'\n",
    "\n",
    "with pd.ExcelWriter(results_file) as writer:\n",
    "    df_sqa.to_excel(writer, sheet_name='SQA_Results', index=False)\n",
    "    df_sa.to_excel(writer, sheet_name='SA_Results', index=False)\n",
    "    df_combined.to_excel(writer, sheet_name='Combined', index=False)\n",
    "    \n",
    "    # Configuration\n",
    "    config = pd.DataFrame([{\n",
    "        'best_known_energy': best_known_energy,\n",
    "        'energy_tolerance': energy_tolerance,\n",
    "        'p_target': p_target,\n",
    "        'num_repetitions': num_repetitions,\n",
    "        'beta_min': beta_range[0],\n",
    "        'beta_max': beta_range[1]\n",
    "    }])\n",
    "    config.to_excel(writer, sheet_name='Config', index=False)\n",
    "\n",
    "print(f\"✓ Results saved to: {results_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook provides a **complete annealing time analysis** combining:\n",
    "\n",
    "### **1. Proper Time Measurements:**\n",
    "- **SQA**: OpenJij's `response.info['execution_time']`\n",
    "- **SA**: Estimated from cooling schedule and sweeps\n",
    "- **Wall Time**: Total computational cost\n",
    "\n",
    "### **2. Quality Metrics:**\n",
    "- Success probability (solution quality)\n",
    "- Time-to-Solution (TTS) for fair comparison\n",
    "\n",
    "### **3. Key Insights:**\n",
    "- **Annealing time** is the core optimization cost\n",
    "- **Overhead** shows framework efficiency\n",
    "- **TTS** reveals true performance (time + quality)\n",
    "\n",
    "### **4. Practical Recommendations:**\n",
    "- Choose num_sweeps that **minimizes TTS**, not execution time\n",
    "- Higher sweeps → better quality but longer time\n",
    "- Optimal point balances speed and success rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
